{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "318px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "name": "「03_3_DFA_Algorithms.ipynb」的副本",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LivesayMe/cse480-notebooks/blob/master/%E3%80%8C03_3_DFA_Algorithms_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksg-YWWeYczF"
      },
      "source": [
        "# DFA Algorithms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "yci24DR0YczN"
      },
      "source": [
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "import sys\n",
        "\n",
        "# -- Detect if in Own Install or in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    OWN_INSTALL = False\n",
        "except:\n",
        "    OWN_INSTALL = True\n",
        "    \n",
        "if OWN_INSTALL:\n",
        "\n",
        "  sys.path[0:0] = ['../../../../..',  '../../../../../3rdparty',  \n",
        "                   '../../../..',  '../../../../3rdparty',  \n",
        "                   '../../..',     '../../../3rdparty', \n",
        "                   '../..',        '../../3rdparty',\n",
        "                   '..',           '../3rdparty' ]\n",
        "\n",
        "else: # In colab\n",
        "  ! if [ ! -d Jove ]; then git clone https://github.com/ganeshutah/Jove Jove; fi\n",
        "  sys.path.append('./Jove')\n",
        "  sys.path.append('./Jove/jove')\n",
        "\n",
        "# -- common imports --\n",
        "from jove.DotBashers import *\n",
        "from jove.Def_md2mc  import *\n",
        "from jove.Def_DFA    import *\n",
        "from jove.LangDef    import *  # for testing DFA actions\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "AsCpq2GxYczO"
      },
      "source": [
        "def mkp_dfa(Q, Sigma, Delta, q0, F):\n",
        "    \"\"\"In : Traits of a DFA\n",
        "       Out: A DFA\n",
        "       Check for partial consistency of the given DFA traits.\n",
        "       If the check passes, make and return a DFA with a partial \n",
        "       Delta.\n",
        "    \"\"\"\n",
        "    newDFA = {\"Q\":Q, \"Sigma\":Sigma, \"Delta\":Delta, \"q0\":q0, \"F\":F}\n",
        "    assert(\n",
        "        is_partially_consistent_dfa(newDFA)\n",
        "    ), \"DFA given to mkp_dfa is not partially consistent. Plz check its components.\"\n",
        "    return(newDFA)\n",
        "\n",
        "def mk_dfa(Q, Sigma, Delta, q0, F):\n",
        "    \"\"\"In : Traits of a DFA\n",
        "       Out: A DFA\n",
        "       Check for structural consistency of the given DFA traits.\n",
        "       If the check passes, make and return a DFA with a total \n",
        "       Delta.\n",
        "    \"\"\"\n",
        "    newDFA = {\"Q\":Q, \"Sigma\":Sigma, \"Delta\":Delta, \"q0\":q0, \"F\":F}\n",
        "    assert(\n",
        "        is_consistent_dfa(newDFA)\n",
        "    ), \"DFA given to mk_dfa is not consistent. Plz check its components.\"\n",
        "    return(newDFA)\n",
        "\n",
        "def totalize_dfa(D):\n",
        "    \"\"\"In : Partially consistent DFA\n",
        "       Out: A consistent DFA \n",
        "       Given a partially specified DFA, make it total by \n",
        "       transitioning to state BH wherever the incoming Delta \n",
        "       has gaps. The returned DFA is structurally consistent.\n",
        "    \"\"\"\n",
        "    assert(\n",
        "        is_partially_consistent_dfa(D)\n",
        "    ), \"DFA given to totalize_dfa is not partially consistent.\"\n",
        "    if set(fn_dom(D[\"Delta\"])) == set(product(D[\"Q\"], D[\"Sigma\"])):\n",
        "        # It is already total!\n",
        "        return D \n",
        "    else:        \n",
        "        # We must introduce a BH state of not already present\n",
        "        # and proceed from there\n",
        "        incoming_Delta = D[\"Delta\"].copy()\n",
        "    \n",
        "        # Gaps in incoming_Delta's transition function are sent\n",
        "        # to the BH (black-hole) state\n",
        "        gaps_in_Tr = { (q,c) : \"BH\" for q in D[\"Q\"] for c in D[\"Sigma\"] \n",
        "                       if (q,c) not in D[\"Delta\"] }\n",
        "    \n",
        "        # We are gonna add a new black-hole-state.\n",
        "        # It must curl back to itself for every symbol in Sigma\n",
        "        bh_self_absorbent_moves = { (\"BH\", c): \"BH\" for c in D[\"Sigma\"] }\n",
        "\n",
        "        # Fill the gaps in incoming_Delta\n",
        "        incoming_Delta.update( gaps_in_Tr )\n",
        "    \n",
        "        # Add in the moves where the black-hole state curls \n",
        "        # back to itself\n",
        "        incoming_Delta.update( bh_self_absorbent_moves )\n",
        "        \n",
        "        # All updates required are accomplished\n",
        "        finished_Delta = incoming_Delta\n",
        "    \n",
        "        # See that we update D[\"Q\"] with the \"BH\" (black-hole) \n",
        "        # state; also return the fixed-up incoming_Delta\n",
        "        return {\"Q\"    : D[\"Q\"] | { \"BH\" }, \n",
        "                \"Sigma\": D[\"Sigma\"],    \n",
        "                \"Delta\": finished_Delta,\n",
        "                \"q0\"   : D[\"q0\"],          \n",
        "                \"F\"    : D[\"F\"] }\n",
        "    \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkdYWTrwYczP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cceee324-93ad-4fcc-e208-99539e55abc7"
      },
      "source": [
        "DFA_B0 = md2mc('''DFA !! DFA for words beginning with 0's\n",
        "I : 0   -> F\n",
        "I : 1   -> B\n",
        "B : 0|1 -> B\n",
        "F : 0|1 -> F\n",
        "''')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating LALR tables\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln1ZXaIuYczQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acde9dee-6466-48aa-b0c4-5b6239b5994f"
      },
      "source": [
        "DFA_B0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Delta': {('B', '0'): 'B',\n",
              "  ('B', '1'): 'B',\n",
              "  ('F', '0'): 'F',\n",
              "  ('F', '1'): 'F',\n",
              "  ('I', '0'): 'F',\n",
              "  ('I', '1'): 'B'},\n",
              " 'F': {'F'},\n",
              " 'Q': {'B', 'F', 'I'},\n",
              " 'Sigma': {'0', '1'},\n",
              " 'q0': 'I'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf4qDEcJYczQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc13f92b-1bf5-4047-c322-f210110c0ab3"
      },
      "source": [
        "DFA_B0[\"Delta\"][('I','0')]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'F'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtqTV1GjYczQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "54b67034-b945-4187-928c-895d3112af51"
      },
      "source": [
        "dotObj_dfa(DFA_B0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f61f59e5c50>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"227pt\" height=\"238pt\"\n viewBox=\"0.00 0.00 227.00 238.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 234)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-234 223,-234 223,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- I -->\n<g id=\"node3\" class=\"node\">\n<title>I</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"109\" cy=\"-84\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-80.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">I</text>\n</g>\n<!-- EMPTY&#45;&gt;I -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;I</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3048,-84C62.6909,-84 71.9407,-84 80.4103,-84\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.5976,-87.5001 90.5976,-84 80.5976,-80.5001 80.5976,-87.5001\"/>\n</g>\n<!-- B -->\n<g id=\"node2\" class=\"node\">\n<title>B</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-146\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-142.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B</text>\n</g>\n<!-- B&#45;&gt;B -->\n<g id=\"edge4\" class=\"edge\">\n<title>B&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M192.8654,-163.7817C192.1628,-173.3149 193.541,-182 197,-182 199.1078,-182 200.443,-178.7749 201.0054,-174.0981\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.509,-173.8248 201.1346,-163.7817 197.5096,-173.7371 204.509,-173.8248\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- B&#45;&gt;B -->\n<g id=\"edge5\" class=\"edge\">\n<title>B&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.3338,-162.8636C186.2877,-180.3779 188.5098,-200 197,-200 203.8983,-200 206.6587,-187.0463 205.281,-172.7944\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.7259,-172.1722 203.6662,-162.8636 201.8166,-173.2957 208.7259,-172.1722\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-203.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- I&#45;&gt;B -->\n<g id=\"edge3\" class=\"edge\">\n<title>I&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M123.928,-94.5175C137.5817,-104.1371 157.9955,-118.5196 173.7789,-129.6397\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.8081,-132.5326 181.9988,-135.431 175.8398,-126.8102 171.8081,-132.5326\"/>\n<text text-anchor=\"middle\" x=\"151\" y=\"-119.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- F -->\n<g id=\"node4\" class=\"node\">\n<title>F</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-22\" rx=\"22\" ry=\"22\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F</text>\n</g>\n<!-- I&#45;&gt;F -->\n<g id=\"edge2\" class=\"edge\">\n<title>I&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M123.928,-73.4825C136.6354,-64.5296 155.1985,-51.4511 170.4344,-40.7166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"172.7923,-43.3369 178.9513,-34.7162 168.7606,-37.6145 172.7923,-43.3369\"/>\n<text text-anchor=\"middle\" x=\"151\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- F&#45;&gt;F -->\n<g id=\"edge6\" class=\"edge\">\n<title>F&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M192.7549,-43.8066C192.3506,-53.5625 193.7656,-62 197,-62 199.0215,-62 200.3323,-58.7041 200.9324,-53.8504\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.4321,-53.9107 201.2451,-43.8066 197.4355,-53.6928 204.4321,-53.9107\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-65.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- F&#45;&gt;F -->\n<g id=\"edge7\" class=\"edge\">\n<title>F&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M189.7985,-42.813C186.5135,-60.8838 188.9141,-80 197,-80 203.5698,-80 206.3864,-67.3803 205.4497,-52.9552\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.8968,-52.3106 204.2015,-42.813 201.9492,-53.1656 208.8968,-52.3106\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKzv5-kLYczR"
      },
      "source": [
        "DFA_E1 = md2mc('''DFA !! accepts words that end in a 1  \n",
        "I : 1   -> F\n",
        "I : 0   -> I\n",
        "F : 1 -> F\n",
        "F : 0 -> I\n",
        "''')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYYdhKxrYczR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9dfa2e68-51c8-4865-ec43-5939c13d1089"
      },
      "source": [
        "dotObj_dfa(DFA_E1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f61f5dd9f28>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"227pt\" height=\"85pt\"\n viewBox=\"0.00 0.00 227.00 85.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 81)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-81 223,-81 223,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- I -->\n<g id=\"node2\" class=\"node\">\n<title>I</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"109\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">I</text>\n</g>\n<!-- EMPTY&#45;&gt;I -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;I</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3048,-22C62.6909,-22 71.9407,-22 80.4103,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.5976,-25.5001 90.5976,-22 80.5976,-18.5001 80.5976,-25.5001\"/>\n</g>\n<!-- I&#45;&gt;I -->\n<g id=\"edge3\" class=\"edge\">\n<title>I&#45;&gt;I</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M102.6208,-39.0373C101.3189,-48.8579 103.4453,-58 109,-58 112.4717,-58 114.6042,-54.4289 115.3975,-49.3529\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.8971,-49.031 115.3792,-39.0373 111.8971,-49.0435 118.8971,-49.031\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- F -->\n<g id=\"node3\" class=\"node\">\n<title>F</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-22\" rx=\"22\" ry=\"22\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F</text>\n</g>\n<!-- I&#45;&gt;F -->\n<g id=\"edge2\" class=\"edge\">\n<title>I&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M127.2337,-22C138.0103,-22 151.9708,-22 164.5692,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.7317,-25.5001 174.7317,-22 164.7317,-18.5001 164.7317,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"151\" y=\"-25.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- F&#45;&gt;I -->\n<g id=\"edge5\" class=\"edge\">\n<title>F&#45;&gt;I</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M178.5288,-9.5151C168.7254,-4.3636 156.3821,-.1807 145,-3 141.0235,-3.985 137.0019,-5.4981 133.1597,-7.2497\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.3818,-4.2287 124.1057,-11.93 134.5962,-10.447 131.3818,-4.2287\"/>\n<text text-anchor=\"middle\" x=\"151\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- F&#45;&gt;F -->\n<g id=\"edge4\" class=\"edge\">\n<title>F&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M188.6298,-42.5808C187.4716,-52.8447 190.2617,-62 197,-62 201.3167,-62 204.0131,-58.2427 205.0891,-52.8436\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.595,-52.6729 205.3702,-42.5808 201.5976,-52.4812 208.595,-52.6729\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-65.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "bAjeTLl4YczS"
      },
      "source": [
        "def step_dfa(D, q, c):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            q (state in D)\n",
        "            c (symbol in D's sigma)\n",
        "       Out: next state of q via c (state in D) \n",
        "    \"\"\"\n",
        "    assert(c in D[\"Sigma\"]), \"step_dfa given c not in Sigma.\"\n",
        "    assert(q in D[\"Q\"]), \"step_dfa given q not in Q.\"\n",
        "    return D[\"Delta\"][(q,c)]\n",
        "\n",
        "def run_dfa(D, s):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            q (state in D)\n",
        "            s (string over D's sigma, including \"\")\n",
        "       Out: next state of q via s (state in D) \n",
        "    \"\"\"    \n",
        "    state = D[\"q0\"]\n",
        "    while s != \"\":\n",
        "        state = step_dfa(D, state, s[0])\n",
        "        s = s[1:]\n",
        "    return state\n",
        "\n",
        "def accepts_dfa(D, s):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            s (string over D's sigma, including \"\")\n",
        "       Out: Boolean (if state after s-run is in D's final).\n",
        "    \"\"\"\n",
        "    return run_dfa(D, s) in D[\"F\"]\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl39eQHoYczS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06155d38-e6d9-4239-8212-cc71c302c506"
      },
      "source": [
        "accepts_dfa(DFA_E1, \"001\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzQdKnYJYczS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d07dd63-5e15-46c4-f2a3-32e34c3f85cf"
      },
      "source": [
        "accepts_dfa(DFA_E1, \"000\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF4i4xnWYczV"
      },
      "source": [
        "DFA_B0_and_E1 = intersect_dfa(DFA_B0, DFA_E1)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjxVp8hMYczW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "feb0b7e7-17be-4753-ebb5-39f7da25223c"
      },
      "source": [
        "dotObj_dfa(DFA_B0_and_E1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f61f5de3c50>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"389pt\" height=\"239pt\"\n viewBox=\"0.00 0.00 388.88 239.44\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 235.4446)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-235.4446 384.8835,-235.4446 384.8835,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-111.5473\" rx=\"27.0966\" ry=\"27.0966\"/>\n<text text-anchor=\"middle\" x=\"118.2976\" y=\"-107.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-111.5473C62.6976,-111.5473 71.9683,-111.5473 80.8159,-111.5473\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-115.0474 90.9246,-111.5473 80.9246,-108.0474 80.9247,-115.0474\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"226.7422\" cy=\"-168.5473\" rx=\"29.795\" ry=\"29.795\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-164.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.2832,-196.5902C215.8184,-207.4327 219.3047,-216.4446 226.7422,-216.4446 231.6231,-216.4446 234.8023,-212.5635 236.2799,-206.8309\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.791,-206.8636 237.2012,-196.5902 232.8192,-206.2364 239.791,-206.8636\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-220.2446\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\) -->\n<g id=\"node6\" class=\"node\">\n<title>\\(F_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-152.5473\" rx=\"32.4945\" ry=\"32.4945\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-152.5473\" rx=\"36.4942\" ry=\"36.4942\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-148.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M256.4288,-164.5098C269.0268,-162.7964 284.0102,-160.7587 298.0083,-158.8549\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"298.5417,-162.3146 307.9787,-157.4989 297.5983,-155.3785 298.5417,-162.3146\"/>\n<text text-anchor=\"middle\" x=\"283.8893\" y=\"-164.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M142.6347,-124.3392C156.9381,-131.8573 175.2763,-141.4961 191.1769,-149.8537\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.7281,-153.0461 200.2083,-154.6007 192.9849,-146.8499 189.7281,-153.0461\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-143.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"226.7422\" cy=\"-54.5473\" rx=\"33.2948\" ry=\"33.2948\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-50.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge11\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M142.6347,-98.7554C155.977,-91.7425 172.8301,-82.8843 187.9405,-74.942\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.8534,-77.8906 197.0768,-70.1399 186.5966,-71.6944 189.8534,-77.8906\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-89.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge10\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.2448,-86.0132C216.1337,-96.9014 219.6328,-105.6943 226.7422,-105.6943 231.4077,-105.6943 234.5185,-101.9075 236.0744,-96.2268\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.5835,-96.3455 237.2397,-86.0132 232.6286,-95.552 239.5835,-96.3455\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-109.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_I\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(B_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-30.5473\" rx=\"30.5947\" ry=\"30.5947\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-26.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_I)</text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M259.5127,-47.862C273.2994,-45.0494 289.4789,-41.7487 303.9931,-38.7877\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.1109,-42.1319 314.2095,-36.7035 303.7116,-35.2731 305.1109,-42.1319\"/>\n<text text-anchor=\"middle\" x=\"283.8893\" y=\"-47.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(B_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M314.8525,-22.0236C303.1734,-19.9337 289.7364,-19.1466 277.8893,-22.5473 272.4778,-24.1006 267.084,-26.4124 261.939,-29.0956\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"259.9173,-26.2208 252.9965,-34.2429 263.4094,-32.2876 259.9173,-26.2208\"/>\n<text text-anchor=\"middle\" x=\"283.8893\" y=\"-26.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_I\\)&#45;&gt;\\(B_I\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(B_I\\)&#45;&gt;\\(B_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M333.1803,-58.9707C332.6823,-69.9604 336.4176,-79.0946 344.3864,-79.0946 349.7404,-79.0946 353.1834,-74.9712 354.7153,-68.9322\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.2018,-69.2392 355.5924,-58.9707 351.2287,-68.6252 358.2018,-69.2392\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-82.8946\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M309.6693,-140.6533C299.3733,-138.6371 288.1179,-137.9307 277.8893,-140.5473 272.109,-142.0259 266.2793,-144.3078 260.7293,-146.9447\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"258.9657,-143.9169 251.7112,-151.6385 262.1976,-150.1262 258.9657,-143.9169\"/>\n<text text-anchor=\"middle\" x=\"283.8893\" y=\"-144.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M333.1426,-187.4025C333.3142,-198.3823 337.0622,-207.0444 344.3864,-207.0444 349.1929,-207.0444 352.4593,-203.314 354.1854,-197.6461\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"357.6992,-197.7933 355.6302,-187.4025 350.7678,-196.8156 357.6992,-197.7933\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-210.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lFvnfpPYczW"
      },
      "source": [
        "DFA_B0_or_E1 = union_dfa(DFA_B0, DFA_E1)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxIu1BECYczW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "f4baca80-ec5c-4cba-b720-dcf007e83ab5"
      },
      "source": [
        "dotObj_dfa(DFA_B0_or_E1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f61f5de3d30>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"397pt\" height=\"237pt\"\n viewBox=\"0.00 0.00 396.88 236.64\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 232.6442)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-232.6442 392.8835,-232.6442 392.8835,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-98.1471\" rx=\"27.0966\" ry=\"27.0966\"/>\n<text text-anchor=\"middle\" x=\"118.2976\" y=\"-94.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-98.1471C62.6976,-98.1471 71.9683,-98.1471 80.8159,-98.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-101.6472 90.9246,-98.1471 80.9246,-94.6472 80.9247,-101.6472\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-159.1471\" rx=\"29.8071\" ry=\"29.8071\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-159.1471\" rx=\"33.795\" ry=\"33.795\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-155.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M142.4198,-111.2331C156.7941,-119.031 175.3784,-129.1128 191.7888,-138.0152\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.1826,-141.1257 200.6414,-142.8177 193.5205,-134.9728 190.1826,-141.1257\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-131.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-37.1471\" rx=\"33.2788\" ry=\"33.2788\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-37.1471\" rx=\"37.2947\" ry=\"37.2947\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-33.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge11\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M142.4198,-85.061C155.9058,-77.745 173.0975,-68.4187 188.7229,-59.9421\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5812,-62.9159 197.7021,-55.0709 187.2433,-56.763 190.5812,-62.9159\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-75.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_I\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(B_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"352.3864\" cy=\"-34.1471\" rx=\"30.5947\" ry=\"30.5947\"/>\n<text text-anchor=\"middle\" x=\"352.3864\" y=\"-30.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_I)</text>\n</g>\n<!-- \\(B_I\\)&#45;&gt;\\(B_I\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(B_I\\)&#45;&gt;\\(B_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M341.1803,-62.5705C340.6823,-73.5601 344.4176,-82.6943 352.3864,-82.6943 357.7404,-82.6943 361.1834,-78.571 362.7153,-72.532\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"366.2018,-72.839 363.5924,-62.5705 359.2287,-72.225 366.2018,-72.839\"/>\n<text text-anchor=\"middle\" x=\"352.3864\" y=\"-86.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(B_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.4431,-21.5447C312.6357,-17.6472 298.6816,-14.899 285.8893,-17.1471 282.2657,-17.7838 278.5667,-18.6392 274.8856,-19.6387\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"273.7966,-16.3115 265.2478,-22.5701 275.8336,-23.0086 273.7966,-16.3115\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-20.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M219.4929,-191.3291C219.4338,-202.2592 223.1836,-211.0444 230.7422,-211.0444 235.7025,-211.0444 239.0225,-207.2609 240.7022,-201.5707\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"244.215,-201.688 241.9915,-191.3291 237.2698,-200.8136 244.215,-201.688\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-214.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\) -->\n<g id=\"node6\" class=\"node\">\n<title>\\(F_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"352.3864\" cy=\"-159.1471\" rx=\"32.4945\" ry=\"32.4945\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"352.3864\" cy=\"-159.1471\" rx=\"36.4942\" ry=\"36.4942\"/>\n<text text-anchor=\"middle\" x=\"352.3864\" y=\"-155.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M264.9506,-159.1471C277.6062,-159.1471 292.1767,-159.1471 305.7491,-159.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.8853,-162.6472 315.8853,-159.1471 305.8852,-155.6472 305.8853,-162.6472\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-162.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M268.0379,-36.7361C277.7565,-36.5894 288.2157,-36.3966 297.8893,-36.1471 302.3761,-36.0313 307.0699,-35.8899 311.7403,-35.7362\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"311.9651,-39.2306 321.8375,-35.3855 311.722,-32.2348 311.9651,-39.2306\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-39.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge10\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M219.5032,-72.6841C219.7303,-83.6684 223.4766,-92.2941 230.7422,-92.2941 235.5103,-92.2941 238.7627,-88.5793 240.4995,-82.921\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"244.0126,-83.0824 241.9812,-72.6841 237.0848,-82.0796 244.0126,-83.0824\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-96.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M318.5441,-145.3915C311.807,-143.2136 304.7059,-141.3013 297.8893,-140.1471 289.2178,-138.6788 280.0649,-139.571 271.4008,-141.6032\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"270.1602,-138.3178 261.5127,-144.4391 272.0901,-145.0465 270.1602,-138.3178\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-143.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M341.1426,-194.0022C341.3142,-204.9821 345.0622,-213.6442 352.3864,-213.6442 357.1929,-213.6442 360.4593,-209.9137 362.1854,-204.2459\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"365.6992,-204.3931 363.6302,-194.0022 358.7678,-203.4154 365.6992,-204.3931\"/>\n<text text-anchor=\"middle\" x=\"352.3864\" y=\"-217.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6duj6d61YczW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "ad4779fa-f02f-4d1e-d755-608af196bde9"
      },
      "source": [
        "dotObj_dfa(min_dfa(DFA_B0_or_E1))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f61f5de3160>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"385pt\" height=\"267pt\"\n viewBox=\"0.00 0.00 384.98 267.04\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 263.0444)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-263.0444 380.9839,-263.0444 380.9839,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-98.1471\" rx=\"27.0966\" ry=\"27.0966\"/>\n<text text-anchor=\"middle\" x=\"118.2976\" y=\"-94.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-98.1471C62.6976,-98.1471 71.9683,-98.1471 80.8159,-98.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-101.6472 90.9246,-98.1471 80.9246,-94.6472 80.9247,-101.6472\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-159.1471\" rx=\"29.8071\" ry=\"29.8071\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-159.1471\" rx=\"33.795\" ry=\"33.795\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-155.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M142.4198,-111.2331C156.7941,-119.031 175.3784,-129.1128 191.7888,-138.0152\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.1826,-141.1257 200.6414,-142.8177 193.5205,-134.9728 190.1826,-141.1257\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-131.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-37.1471\" rx=\"33.2788\" ry=\"33.2788\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-37.1471\" rx=\"37.2947\" ry=\"37.2947\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-33.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M142.4198,-85.061C155.9058,-77.745 173.0975,-68.4187 188.7229,-59.9421\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5812,-62.9159 197.7021,-55.0709 187.2433,-56.763 190.5812,-62.9159\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-75.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_I\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(B_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"346.4366\" cy=\"-37.1471\" rx=\"30.5947\" ry=\"30.5947\"/>\n<text text-anchor=\"middle\" x=\"346.4366\" y=\"-33.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_I)</text>\n</g>\n<!-- \\(B_I\\)&#45;&gt;\\(B_I\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(B_I\\)&#45;&gt;\\(B_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M336.3338,-66.0541C336.0026,-76.8268 339.3702,-85.6943 346.4366,-85.6943 351.0739,-85.6943 354.1183,-81.8754 355.5697,-76.2053\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"359.0725,-76.3416 356.5393,-66.0541 352.1042,-75.676 359.0725,-76.3416\"/>\n<text text-anchor=\"middle\" x=\"346.4366\" y=\"-89.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(B_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M318.7251,-24.2626C312.0432,-21.7315 304.8265,-19.4562 297.8893,-18.1471 290.2738,-16.7099 282.2716,-17.1773 274.5514,-18.6872\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"273.457,-15.3537 264.6212,-21.2001 275.1743,-22.1398 273.457,-15.3537\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-21.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M225.1227,-192.59C225.2362,-202.927 227.1094,-211.0444 230.7422,-211.0444 233.0695,-211.0444 234.6746,-207.713 235.5576,-202.6009\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.0497,-202.8382 236.3617,-192.59 232.0721,-202.2776 239.0497,-202.8382\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-214.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M220.1953,-191.5019C217.8516,-210.842 221.3672,-229.0444 230.7422,-229.0444 238.4326,-229.0444 242.1802,-216.7958 241.985,-201.7182\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"245.4607,-201.2409 241.2891,-191.5019 238.4768,-201.7166 245.4607,-201.2409\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-232.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M267.9855,-37.1471C280.0615,-37.1471 293.5155,-37.1471 305.824,-37.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.8382,-40.6472 315.8382,-37.1471 305.8382,-33.6472 305.8382,-40.6472\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-40.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M219.5032,-72.6841C219.7303,-83.6684 223.4766,-92.2941 230.7422,-92.2941 235.5103,-92.2941 238.7627,-88.5793 240.4995,-82.921\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"244.0126,-83.0824 241.9812,-72.6841 237.0848,-82.0796 244.0126,-83.0824\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-96.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "iNoQAXJKYczX"
      },
      "source": [
        "## DFA complementation\n",
        "\n",
        "DFA complementation works by flipping the final and non-final states. We must check that the DFA is totalized before we embark on that, as the 'black-hole' state will now become 'white-hole' (a final state from which all symbols lead back to itself)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "hP4ZcRPBYczX"
      },
      "source": [
        "def comp_dfa(D):\n",
        "    \"\"\"In : D (DFA : partially consistent)\n",
        "       Out: Consistent DFA that is D's complement.\n",
        "       Before we begin, make D total. This is crucial, \n",
        "       as the black-hole states if any\n",
        "       become \"white-hole\" states in the complemented DFA \n",
        "       (i.e. really turn into accepting \n",
        "       states from which one can't get out).\n",
        "       Then flip the FINAL and NON-FINAL states.\n",
        "    \"\"\"\n",
        "    Dtot = totalize_dfa(D)\n",
        "    return mk_dfa(D[\"Q\"],D[\"Sigma\"],D[\"Delta\"],D[\"q0\"],D[\"Q\"]-D[\"F\"])\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5wkRGdeYczX"
      },
      "source": [
        "DFA_comp_B0_or_E1 = comp_dfa(DFA_B0_or_E1)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWqsskAIYczY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "344e3907-d1ed-421c-d643-266aefde3ccd"
      },
      "source": [
        "dotObj_dfa(DFA_comp_B0_or_E1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f61f5de34a8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"393pt\" height=\"243pt\"\n viewBox=\"0.00 0.00 392.98 243.44\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 239.4446)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-239.4446 388.9839,-239.4446 388.9839,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122.2976\" cy=\"-115.5473\" rx=\"27.1222\" ry=\"27.1222\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122.2976\" cy=\"-115.5473\" rx=\"31.0965\" ry=\"31.0965\"/>\n<text text-anchor=\"middle\" x=\"122.2976\" y=\"-111.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.0536,-115.5473C62.3696,-115.5473 71.722,-115.5473 80.7745,-115.5473\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7965,-119.0474 90.7964,-115.5473 80.7964,-112.0474 80.7965,-119.0474\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"234.7422\" cy=\"-172.5473\" rx=\"29.795\" ry=\"29.795\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-168.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M224.2832,-200.5902C223.8184,-211.4327 227.3047,-220.4446 234.7422,-220.4446 239.6231,-220.4446 242.8023,-216.5635 244.2799,-210.8309\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"247.791,-210.8636 245.2012,-200.5902 240.8192,-210.2364 247.791,-210.8636\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-224.2446\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(F_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"350.4366\" cy=\"-156.5473\" rx=\"32.4942\" ry=\"32.4942\"/>\n<text text-anchor=\"middle\" x=\"350.4366\" y=\"-152.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M264.5364,-168.4269C277.682,-166.6089 293.3778,-164.4383 307.7347,-162.4528\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"308.4703,-165.8844 317.8965,-161.0474 307.5113,-158.9504 308.4703,-165.8844\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-168.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"234.7422\" cy=\"-58.5473\" rx=\"33.2948\" ry=\"33.2948\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-54.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge10\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M224.2448,-90.0132C224.1337,-100.9014 227.6328,-109.6943 234.7422,-109.6943 239.4077,-109.6943 242.5185,-105.9075 244.0744,-100.2268\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"247.5835,-100.3455 245.2397,-90.0132 240.6286,-99.552 247.5835,-100.3455\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-113.4943\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_I\\) -->\n<g id=\"node6\" class=\"node\">\n<title>\\(B_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"350.4366\" cy=\"-34.5473\" rx=\"30.5892\" ry=\"30.5892\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"350.4366\" cy=\"-34.5473\" rx=\"34.5946\" ry=\"34.5946\"/>\n<text text-anchor=\"middle\" x=\"350.4366\" y=\"-30.8473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_I)</text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M267.2774,-51.7981C279.4069,-49.2819 293.3859,-46.3821 306.3793,-43.6867\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.4536,-47.0384 316.5342,-41.5801 306.0317,-40.1843 307.4536,-47.0384\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-50.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M319.7178,-145.3877C308.9514,-142.9118 296.8214,-141.7508 285.8893,-144.5473 280.109,-146.0259 274.2793,-148.3078 268.7293,-150.9447\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"266.9657,-147.9169 259.7112,-155.6385 270.1976,-154.1262 266.9657,-147.9169\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-148.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M339.5642,-187.6133C339.4492,-198.3632 343.0733,-207.0444 350.4366,-207.0444 355.2687,-207.0444 358.4905,-203.3057 360.102,-197.6972\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"363.5957,-197.9584 361.3089,-187.6133 356.6453,-197.1265 363.5957,-197.9584\"/>\n<text text-anchor=\"middle\" x=\"350.4366\" y=\"-210.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M150.3821,-129.7838C164.9267,-137.1567 182.8564,-146.2455 198.4408,-154.1455\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"197.2879,-157.4851 207.7899,-158.8847 200.453,-151.2415 197.2879,-157.4851\"/>\n<text text-anchor=\"middle\" x=\"177.5952\" y=\"-149.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge11\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M150.3821,-101.3108C164.1725,-94.3202 181.0061,-85.787 195.9984,-78.1871\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"197.7147,-81.2412 205.0516,-73.5979 194.5496,-74.9976 197.7147,-81.2412\"/>\n<text text-anchor=\"middle\" x=\"177.5952\" y=\"-93.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(B_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M316.868,-25.3279C306.7771,-23.9035 295.766,-23.7122 285.8893,-26.5473 280.4778,-28.1006 275.084,-30.4124 269.939,-33.0956\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"267.9173,-30.2208 260.9965,-38.2429 271.4094,-36.2876 267.9173,-30.2208\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-30.3473\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_I\\)&#45;&gt;\\(B_I\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(B_I\\)&#45;&gt;\\(B_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M339.5616,-67.3893C339.5616,-78.3367 343.1866,-87.0946 350.4366,-87.0946 355.1944,-87.0946 358.391,-83.3229 360.0265,-77.6359\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"363.5399,-77.7472 361.3116,-67.3893 356.5943,-76.8761 363.5399,-77.7472\"/>\n<text text-anchor=\"middle\" x=\"350.4366\" y=\"-90.8946\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nFdzisZYczY"
      },
      "source": [
        "DFA_comp_compB0_or_compE1 = comp_dfa(union_dfa(comp_dfa(DFA_B0), comp_dfa(DFA_E1)))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqJLNo4TYczY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "b1862f4c-6cba-40ec-9f37-388ac8e6ac3c"
      },
      "source": [
        "dotObj_dfa(DFA_comp_compB0_or_compE1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f61f5dd9320>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"389pt\" height=\"291pt\"\n viewBox=\"0.00 0.00 388.88 290.64\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 286.6442)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-286.6442 384.8835,-286.6442 384.8835,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-106.1471\" rx=\"27.0966\" ry=\"27.0966\"/>\n<text text-anchor=\"middle\" x=\"118.2976\" y=\"-102.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-106.1471C62.6976,-106.1471 71.9683,-106.1471 80.8159,-106.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-109.6472 90.9246,-106.1471 80.9246,-102.6472 80.9247,-109.6472\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"226.7422\" cy=\"-180.1471\" rx=\"29.795\" ry=\"29.795\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-176.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.2832,-208.19C215.8184,-219.0325 219.3047,-228.0444 226.7422,-228.0444 231.6231,-228.0444 234.8023,-224.1633 236.2799,-218.4307\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.791,-218.4634 237.2012,-208.19 232.8192,-217.8361 239.791,-218.4634\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-231.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(F_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-180.1471\" rx=\"32.4945\" ry=\"32.4945\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-180.1471\" rx=\"36.4942\" ry=\"36.4942\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-176.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M256.7332,-180.1471C269.1018,-180.1471 283.7299,-180.1471 297.4563,-180.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"297.725,-183.6472 307.7249,-180.1471 297.7249,-176.6472 297.725,-183.6472\"/>\n<text text-anchor=\"middle\" x=\"283.8893\" y=\"-183.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M141.0311,-121.6599C156.1574,-131.9817 176.287,-145.7176 193.2374,-157.2842\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.5352,-160.3599 201.7682,-163.1054 195.4808,-154.5778 191.5352,-160.3599\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-146.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"226.7422\" cy=\"-33.1471\" rx=\"33.2948\" ry=\"33.2948\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-29.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M141.0311,-90.8439C155.417,-81.16 174.3283,-68.4298 190.7262,-57.3914\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.6939,-60.286 199.035,-51.7983 188.7849,-54.4791 192.6939,-60.286\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-77.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.4973,-66.1065C221.6033,-76.2941 223.3516,-84.2941 226.7422,-84.2941 228.8614,-84.2941 230.339,-81.1691 231.175,-76.3381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.6848,-76.3521 231.9871,-66.1065 227.7068,-75.7982 234.6848,-76.3521\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-88.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.8985,-65.1546C214.711,-84.2871 217.9922,-102.2941 226.7422,-102.2941 233.9199,-102.2941 237.4177,-90.1769 237.2354,-75.2612\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"240.7202,-74.9095 236.586,-65.1546 233.7346,-75.3585 240.7202,-74.9095\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-106.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M338.7834,-216.3083C339.0031,-226.6612 340.8708,-234.6442 344.3864,-234.6442 346.6386,-234.6442 348.2145,-231.368 349.114,-226.2913\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"352.6024,-226.5758 349.9894,-216.3083 345.6292,-225.9643 352.6024,-226.5758\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-238.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M333.6747,-215.2073C331.6752,-234.6969 335.2458,-252.6442 344.3864,-252.6442 351.8846,-252.6442 355.6346,-240.5672 355.6364,-225.4688\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"359.1172,-225.0101 355.0981,-215.2073 352.1268,-225.3769 359.1172,-225.0101\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-256.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "YeJ2-vrqYczZ"
      },
      "source": [
        "## DFA Union\n",
        "\n",
        "DFA union has a straightforward definition as in the book. We march the DFAs in tandem. We accept if either DFA accepts_dfa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "j_3uwc0-YczZ"
      },
      "source": [
        "def union_dfa(D1in, D2in):\n",
        "    \"\"\"In : D1in (consistent DFA)\n",
        "            D2in (consistent DFA)\n",
        "       Out: DFA for language union of D1in, D2in (consistent DFA). \n",
        "    \"\"\"\n",
        "    assert(is_consistent_dfa(D1in)), \"Inconsist. DFA1 in union_dfa\"\n",
        "    assert(is_consistent_dfa(D2in)), \"Inconsist. DFA2 in union_dfa\"\n",
        "    if (D1in[\"Sigma\"] != D2in[\"Sigma\"]):\n",
        "        print(\"Union on DFA with different alphabets.\")\n",
        "        print(\"Making alphabets the same (taking unions).\")\n",
        "        Sigma = D1in[\"Sigma\"] | D2in[\"Sigma\"]\n",
        "        D1   = copy.deepcopy(D1in)\n",
        "        D2   = copy.deepcopy(D2in)\n",
        "        D1[\"Sigma\"] = Sigma\n",
        "        D2[\"Sigma\"] = Sigma\n",
        "        D1 = totalize_dfa(D1)\n",
        "        D2 = totalize_dfa(D2)\n",
        "    else:\n",
        "        D1 = totalize_dfa(D1in)\n",
        "        D2 = totalize_dfa(D2in)\n",
        "   \n",
        "    # The states can be anything in the cartesian product\n",
        "    Q     = set(product(D1[\"Q\"], D2[\"Q\"]))\n",
        "    \n",
        "    # Accept if one of the DFAs accepts\n",
        "    F     = (set(product(D1[\"F\"], D2[\"Q\"])) | \n",
        "             set(product(D1[\"Q\"], D2[\"F\"])))\n",
        "    \n",
        "    # Start a lock-step march from the respective q0\n",
        "    q0    = (D1[\"q0\"], D2[\"q0\"])\n",
        "    \n",
        "    # The transition function attempts to march both\n",
        "    # DFAs in lock-step per their own transition functions\n",
        "    Delta = { ((q1,q2),ch) : (q1p, q2p) \n",
        "               for q1 in D1[\"Q\"] for q1p in D1[\"Q\"] \n",
        "               for q2 in D2[\"Q\"] for q2p in D2[\"Q\"] \n",
        "               for ch in D1[\"Sigma\"] \n",
        "               if D1[\"Delta\"][(q1,ch)] == q1p and\n",
        "                  D2[\"Delta\"][(q2,ch)] == q2p }\n",
        "                                                          \n",
        "    return pruneUnreach(\n",
        "        mk_dfa(Q, D1[\"Sigma\"], Delta, q0, F))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "iKmE-cjTYcza"
      },
      "source": [
        "def intersect_dfa(D1in, D2in):\n",
        "    \"\"\"In : D1in (consistent DFA)\n",
        "            D2in (consistent DFA)\n",
        "       Out: DFA for language intersection of D1in, D2in (consistent DFA). \n",
        "    \"\"\"\n",
        "    assert(is_consistent_dfa(D1in)), \"Inconsist. DFA1 in intersect_dfa\"\n",
        "    assert(is_consistent_dfa(D2in)), \"Inconsist. DFA2 in intersect_dfa\"\n",
        "    if (D1in[\"Sigma\"] != D2in[\"Sigma\"]):\n",
        "        print(\"Intersection on DFA with different alphabets.\")\n",
        "        print(\"Making alphabets the same (taking unions).\")\n",
        "        Sigma = D1in[\"Sigma\"] | D2in[\"Sigma\"]\n",
        "        D1   = copy.deepcopy(D1in)\n",
        "        D2   = copy.deepcopy(D2in)\n",
        "        D1[\"Sigma\"] = Sigma\n",
        "        D2[\"Sigma\"] = Sigma\n",
        "        D1 = totalize_dfa(D1)\n",
        "        D2 = totalize_dfa(D2)\n",
        "    else:\n",
        "        D1 = totalize_dfa(D1in)\n",
        "        D2 = totalize_dfa(D2in)\n",
        " \n",
        "    Q     = set(product(D1[\"Q\"], D2[\"Q\"]))\n",
        "    \n",
        "    # This is the only difference with the union:\n",
        "    # The final states are those when both DFA accept\n",
        "    F     = set(product(D1[\"F\"], D2[\"F\"]))\n",
        "           \n",
        "    q0    = (D1[\"q0\"], D2[\"q0\"])\n",
        "    Delta = { ((q1,q2),ch) : (q1p, q2p) \n",
        "               for q1 in D1[\"Q\"] for q1p in D1[\"Q\"] \n",
        "               for q2 in D2[\"Q\"] for q2p in D2[\"Q\"] \n",
        "               for ch in D1[\"Sigma\"] \n",
        "               if D1[\"Delta\"][(q1,ch)] == q1p and\n",
        "                  D2[\"Delta\"][(q2,ch)] == q2p }\n",
        "                                                          \n",
        "    return pruneUnreach(\n",
        "        mk_dfa(Q, D1[\"Sigma\"], Delta, q0, F))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "SsoQ3mvlYcza"
      },
      "source": [
        "### Eliminating unreachable states\n",
        "\n",
        "Let us write the code for eliminating unreachable states. Function pruneUnreach(DFA) returns a new DFA with unreachable states in the input DFA removed (all transitions from them are also removed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "tlDo_w0VYczb"
      },
      "source": [
        "def pruneUnreach(D):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "       Out: Consistent DFA.\n",
        "       Given a consistent (and of course total) DFA D,\n",
        "       returns a new (consistent) DFA with unreachable \n",
        "       states in D removed. Transitions from each unreachable \n",
        "       state are also removed. Reachable states are those that\n",
        "       can be reached in |D[\"Q\"]| - 1 steps or less.\n",
        "    \"\"\"\n",
        "    Nsteps   = len(D[\"Q\"]) - 1 # Search this far\n",
        "    Frontier = set({D[\"q0\"]})  # BFS frontier\n",
        "    AccumF   = Frontier        # Used to accumulate Frontier changes\n",
        "    for n in range(Nsteps):\n",
        "        for q in Frontier:\n",
        "            for ch in D[\"Sigma\"]:\n",
        "                AccumF = AccumF | set({step_dfa(D, q, ch)})\n",
        "        Frontier = AccumF\n",
        "        \n",
        "    newQ     = Frontier\n",
        "    newF     = D[\"F\"] & Frontier\n",
        "    newDelta = dict({ ((q,ch),qp) \n",
        "                      for ((q,ch),qp) in fn_trans(D[\"Delta\"]) \n",
        "                      if q in Frontier })\n",
        "    return mk_dfa(Frontier, D[\"Sigma\"], newDelta, D[\"q0\"], newF)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "fSHIZGFaYczc"
      },
      "source": [
        "# DFA Isomorphism\n",
        "\n",
        "This routine is handy to check whether two DFA are isomorphic. Given they are rooted at q0, the isomorphism-check is linear in the number of edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "1EEDgCClYczc"
      },
      "source": [
        "def iso_dfa(D1,D2):\n",
        "    \"\"\"Given consistent and total DFAs D1 and D2,\n",
        "       check whether they are isomorphic. Two DFAs\n",
        "       are isomorphic if they have the same number\n",
        "       of states and are language-equivalent. (One would\n",
        "       then be able to match-up state for state and transition\n",
        "       for transition.)\n",
        "    \"\"\"\n",
        "    assert(is_consistent_dfa(D1)), \"Inconsist. DFA1 in iso_dfa\"\n",
        "    assert(is_consistent_dfa(D2)), \"Inconsist. DFA2 in iso_dfa\"\n",
        "    return (len(D1[\"Q\"]) == len(D2[\"Q\"]) and\n",
        "            langeq_dfa(D1, D2))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "nzS0DiIeYczc"
      },
      "source": [
        "def langeq_dfa(D1, D2, gen_counterex=False):\n",
        "    \"\"\"Given consistent and total DFAs D1 and D2,\n",
        "       check whether they are language-equivalent. \n",
        "       gen_counterex is a flag that triggers the\n",
        "        printing of a counter-example showing the\n",
        "        pairs that were marched in tandem till a\n",
        "        difference was found.\n",
        "        \n",
        "       Two DFAs are language-equivalent if they \n",
        "       accept the same set of strings. We determine\n",
        "       this through a joint depth-first walk of the \n",
        "       two DFAs until we detect a difference (return\n",
        "       False then) or all pairs of states have been\n",
        "       visited (return True then).\n",
        "    \"\"\"\n",
        "    if D1[\"Sigma\"] != D2[\"Sigma\"]:\n",
        "        print(\"The DFA cannot be compared, as their\", end=\"\")\n",
        "        print(\" alphabets are different; namely:\")\n",
        "        print(\"Sigma1 = \", D1[\"Sigma\"])\n",
        "        print(\"Sigma2 = \", D2[\"Sigma\"])\n",
        "        return False\n",
        "    else:\n",
        "        (eqStatus, cex_path) = h_langeq_dfa(D1[\"q0\"], D1,\n",
        "                                            D2[\"q0\"], D2, \n",
        "                                            Visited=[])\n",
        "        if not eqStatus:\n",
        "            if gen_counterex:\n",
        "                print(\"The DFA are NOT language equivalent!\")\n",
        "                print(\"Path leading to counterexample is: \")\n",
        "                print(cex_path)\n",
        "        return eqStatus # True or False\n",
        "\n",
        "def same_status(q1, D1, q2, D2):\n",
        "    \"\"\"Check if q1,q2 are both accepting\n",
        "       or both non-accepting wrt D1,D2 resply.\n",
        "    \"\"\"\n",
        "    return (q1 in D1[\"F\"]) == (q2 in D2[\"F\"])\n",
        "\n",
        "def h_langeq_dfa(q1, D1, q2, D2, Visited):\n",
        "    \"\"\"Helper for langeq_dfa. \n",
        "       If (q1,q2) is in Visited, no screw-up so far, so\n",
        "        continue. Else if they agree in status, recursively\n",
        "        check for all reachable configurations (a DFS in\n",
        "        recursion). Else (if they differ in status),\n",
        "        then return (False, Visited) where the latter is\n",
        "        the counter-example trace.  \n",
        "    \"\"\"\n",
        "    if (q1,q2) in Visited:\n",
        "        return (True, Visited)\n",
        "    else:\n",
        "        extVisited = Visited + [(q1,q2)]\n",
        "        if not same_status(q1,D1,q2,D2):\n",
        "            return (False, extVisited)\n",
        "        else:\n",
        "            l_nxt_status = list(\n",
        "            map(lambda symb:\n",
        "                h_langeq_dfa(D1[\"Delta\"][(q1,symb)], D1,\n",
        "                             D2[\"Delta\"][(q2,symb)], D2,\n",
        "                             extVisited),\n",
        "                D1[\"Sigma\"]))\n",
        "            l_rejects = list(filter(lambda x: x[0]==False, l_nxt_status))\n",
        "            if l_rejects==[]:\n",
        "                return (True, extVisited)\n",
        "            else:\n",
        "                return l_rejects[0] # which is the first offending (status,cex)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaxaeopDYczd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e095c3-89aa-47bb-a0ee-3bccbbcb7433"
      },
      "source": [
        "langeq_dfa( DFA_comp_compB0_or_compE1 , DFA_B0_and_E1 )"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhGUjJkYcze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937d15ed-1d4f-4994-b4d9-54d8b464127a"
      },
      "source": [
        "iso_dfa( DFA_comp_compB0_or_compE1 , DFA_B0_and_E1 )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUhoHouaYcze"
      },
      "source": [
        "min_DFA_B0_or_E1 = min_dfa(DFA_B0_or_E1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgNcLRRKYcze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695e622e-048a-4aec-d6cd-b9282dac215d"
      },
      "source": [
        "langeq_dfa(DFA_B0_or_E1, min_DFA_B0_or_E1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3NwZ52wYcze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874b5520-6878-4045-974f-42dff763a3ff"
      },
      "source": [
        "iso_dfa(DFA_B0_or_E1, min_DFA_B0_or_E1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "0IvjbSsDYczf"
      },
      "source": [
        "# DFA Minimization\n",
        "\n",
        "This is a good juncture at which to introduce DFA minimization. \n",
        "\n",
        "## Definition of DFA minimization\n",
        "\n",
        "We define minimization only for consistent DFA.\n",
        " \n",
        "> _A consistent DFA D is minimal if it satisfies two properties_\n",
        " \n",
        ">  1. There should not be any unreachable states (from the start state) in it\n",
        " \n",
        ">  2. For any pair of distinct states $(s_1,s_2)$ in $D$, we must not have the case that for all strings $s$ in $\\Sigma^*$, $\\hat{\\delta}(s_1,s) = \\hat{\\delta}(s_2,s)$.\n",
        "\n",
        "\n",
        "We don't want useless states and we don't want redundant states. For instance, let me make a redundant DFA with duplicate states, below. Then you can easily see how even bloated DFAs can recognize the same language. After seeing this fact, we will introduce you to a DFA minimization algorithm.\n",
        "\n",
        "First, let's learn how to deliberately bloat a DFA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "ra1QZ0DPYczf"
      },
      "source": [
        "## DFA minimization algorithm (high level)\n",
        "\n",
        "Having seen two examples of bloated DFA, we now define a minimization algorithm. Here is the gist. The actual algorithm is in the code that follows.\n",
        "\n",
        "1. Put the states into two equivalence classes (EC):\n",
        "\n",
        " a. All non-final states are in one EC, say NF\n",
        " b. All final states are in another EC, say F\n",
        " c. We call any (sa,sb) such that sa in NF and sb in F as **zero-distinguishable** states, as \n",
        "    a $\\varepsilon$ string can distinguish sa and sb (meaning, when sa is evolved through $\\varepsilon$ or $sb$ is evolved through $\\varepsilon$, the resulting state is the same -- sa or sb)\n",
        "    \n",
        "     * \"Evolved through\" means $\\hat{\\delta}(sa,\\varepsilon) = sa$, and similarly for sb\n",
        "     \n",
        "     * In our example DFA d34bl, IF is zero-distinguishable from all other states\n",
        " \n",
        "2. In general, we have $k$-distinguishable states for $k>0$ (above step discussed $k=0$ as zero-distinguishability)\n",
        "\n",
        "3. Split states:\n",
        " \n",
        " a. Take a state pair $(s_1,s_2)$ such that they are not $k$ distinguishable.\n",
        " b. Take $c\\in\\Sigma$\n",
        " c. If $\\delta(s_1,c) = sn_1$ and $\\delta(s_2,c) = sn_2$ and $(sn_1,sn_2)$ are $k$-distinguishable, mark $(s_1,s_2)$ as $k+1$-distinguishable. \n",
        " \n",
        "4. Repeat the above process till across one sweep, the distinguishability relation does not change.\n",
        "\n",
        "5. Take all maximal sets of pairs of states that have not been found distinguishable yet. Pick a representative from each such maximal set. These states are in the final DFA. \n",
        "\n",
        "6. Go by the state transitions of the representative states. (The remaining states in the equivalence classes are not necessary.)\n",
        "\n",
        "  * In our example, all pairs in $\\{A,A1\\} \\times \\{B,B1\\}$ will be 1-distinguishable (distinction made by $0$)\n",
        "  \n",
        "  * The final equivalence classes will be $\\{IF\\}$, and then $\\{A,A1\\}$, and $\\{B,B1\\}$.\n",
        "  \n",
        "\n",
        "<span style=\"color:blue\"> **Clearly, the above algorithm cannot make full sense till you see how it can be worked out \"by hand\" using some pictures. This is what we will now do before showing you the actual code.\n",
        "\n",
        "** </span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "GoCwsV_lYczf"
      },
      "source": [
        "## A fully worked-out example\n",
        "\n",
        "<font size=\"3\"> \n",
        "\n",
        "This is the initial display of a matrix (only the lower half shown, as the upper half is symmetric). The matrix shows \".\" which are points at which state pairs \"collide.\" The dots in this figure allow for these pairs to collide (we show pairs only one way, i.e. (P,Q) and not the other way i.e. (Q,P) also).\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "bNMxINalYczf"
      },
      "source": [
        "<font size=\"4\"> \n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "A   .\n",
        "\n",
        "A1  .   .\n",
        "\n",
        "B   .   .   .\n",
        "\n",
        "B1  .   .   .   .\n",
        "\n",
        "    IF  A   A1  B\n",
        "    \n",
        "The above is a convenient arrangement to talk about these pairs:\n",
        "\n",
        "\n",
        "(A, IF),\n",
        "\n",
        "(A1, IF), (A1, A)\n",
        "\n",
        "(B, IF),  (B, A),  (B, A1)\n",
        "\n",
        "(B1, IF), (B1, A), (B1, A1), (B1, B)\n",
        "\n",
        "Now, here is how the computation proceeds for this example:\n",
        "===========================================================\n",
        "\n",
        "Frame-0              Frame-1                Frame-2                \n",
        " \n",
        "A   -1                A   0                  A   0                 \n",
        "\n",
        "A1  -1   -1           A1  0   -1             A1  0   -1            \n",
        " \n",
        "B   -1   -1  -1       B   0   -1   -1        B   0   1   1         \n",
        "\n",
        "B1  -1   -1  -1  -1   B1  0   -1   -1  -1    B1  0   1   1   -1    \n",
        "\n",
        "    IF   A   A1  B        IF  A    A1  B         IF  A   A1  B         \n",
        "    \n",
        "    \n",
        "Frame-3 = Frame-2   \n",
        "\n",
        "A   0 \n",
        "\n",
        "A1  0   -1\n",
        "\n",
        "B   0   1   1\n",
        "\n",
        "B1  0   1   1   -1\n",
        "\n",
        "    IF  A   A1  B   \n",
        "``` \n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Let's see another example as well. We will explain the second \n",
        "example (we leave the above example wrt **D34bl** as something you can explain).\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "I_ToujvYYczg"
      },
      "source": [
        "\n",
        "Now, here is how the computation proceeds for this example:\n",
        "-------------------------------------------------------- \n",
        " \n",
        " <br>\n",
        " \n",
        "<font size=\"3\"> \n",
        "\n",
        "\n",
        "```\n",
        " \n",
        "Frame-0                  Frame-1                   Frame-2                    \n",
        "                                                                                                     \n",
        "S2  -1                   S2   0                    S2   0                     \n",
        "\n",
        "S3  -1  -1               S3   0  -1                S3   0  -1                 \n",
        "\n",
        "S4  -1  -1  -1           S4  -1   0   0            S4   2   0   0             \n",
        "\n",
        "S5  -1  -1  -1  -1       S5  -1   0   0  -1        S5   2   0   0  -1         \n",
        "\n",
        "S6  -1  -1  -1  -1  -1   S6   0  -1  -1   0   0    S6   0   1   1   0   0     \n",
        "\n",
        "    S1  S2  S3  S4  S5       S1  S2  S3  S4  S5        S1  S2  S3  S4  S5        \n",
        "\n",
        "Initial                  0-distinguishable         1-distinguishable                         \n",
        "     \n",
        "     \n",
        "Frame-3                 Frame-4     \n",
        "                        =\n",
        "                        Frame-3\n",
        "\n",
        "S2   0\n",
        "\n",
        "S3   0  -1\n",
        "\n",
        "S4   2   0   0\n",
        "\n",
        "S5   2   0   0  -1\n",
        "\n",
        "S6   0   1   1   0   0\n",
        "\n",
        "    S1  S2  S3  S4  S5\n",
        "    \n",
        "2-distinguishable \n",
        "     \n",
        "```\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "JcOxoYC9Yczg"
      },
      "source": [
        "Here is the algorithm, going frame by frame.\n",
        "\n",
        "- Initial Frame: \n",
        "\n",
        "     The initial frame is drawn to clash all _combinations_ of states taken two at a time.\n",
        "     Since we have 6 states, we have $6\\choose 2$ = $15$ entries. We put a -1 against each\n",
        "     such pair to denote that they have not been found distinguishable yet.\n",
        "\n",
        "- Frame *0-distinguishable*: We now put a 0 where a pair of states is 0-distinguishable. This means the states are distinguisable after consuming $\\varepsilon$. This of course means that the states are themselves distinguishable. This is only possible if one is a final state and the other is not (in that case, one state, after consuming $\\varepsilon$ accepts_dfa, and another state after consuming $\\varepsilon$ does not accept.\n",
        "\n",
        "  - So for instance, notice that (S3,S1) and (S4,S2) are 0-distinguishable, meaning that one is a final and the other is a non-final state.\n",
        "\n",
        "- Frame *1-distinguishable*: We now put a 1 where a pair of states is 1-distinguishable. This means the states are distinguisable after consuming a string of length $1$ (a single symbol). This is only possible if one state transitions to a final state and the other transitions to a non-final state after consuming a member of $\\Sigma$. \n",
        "\n",
        "  State pairs (S6,S2) and (S6,S3) are of this kind. While both S6 and S2 are final states (hence _0-indistinguishable_), after consuming an 'a' (or a 'b') they respectively go to a final/non-final state.\n",
        " This means that\n",
        "\n",
        "  - after processing **the same symbol** one state -- let's say pre_p -- finds itself landing in a state p and another state  -- let's say pre_q -- finds itself landing in a state q such that (p,q) is 0-distinguishable.\n",
        "  \n",
        "  - When this happens, states pre-p and pre-q are **1-distinguishable**.\n",
        "\n",
        "- Frame *2-distinguishable*: We now put a 2 where a pair of states is 2-distinguishable. This means the states are distinguisable after consuming a string of length $2$ (a string of length $2$). This is only possible if one state transitions to a state (say p) and the other transitions to state (say q) after consuming a member of $\\Sigma$ such that (p,q) is **1-distinguishable**. State pairs (S5,S1) and (S4,S1) are 2-distinguishable because\n",
        "\n",
        "  - after processing **the same symbol** one state -- let's say pre_p -- finds itself landing in a state p and another state  -- let's say pre_q -- finds itself landing in a state q such that (p,q) is 0-distinguishable.\n",
        "  \n",
        "  - When this happens, states pre-p and pre-q are **1-distinguishable**.\n",
        "  \n",
        "  - One example is this:\n",
        "  \n",
        "    - S5 and S1 are 2-distinguishable.\n",
        "    \n",
        "    - This is because after seeing an 'aa', S1 lands in a non-final state while S5 lands in a final state\n",
        "    \n",
        "    - Observe that \"aa\" = \"a\" + \"a\" . Thus, after eating the first \"a\", S1 lands in S2 while S5 lands in S6, and (S2,S6) have already been deemed 1-distinguishable.\n",
        "    \n",
        "    - Thus, when we mark (S5,S1) as 2-distinguishable, we are sending the matrix entry at (S5,S2) from \n",
        "      -1 to 2\n",
        " \n",
        "\n",
        "\n",
        "  - Now, in search of 3-distinguishability, we catch hold of all pairs in the matrix and see if we can send another -1 entry to \"3\". This appears not to happen. \n",
        "  \n",
        "     - Thus, if (S2,S3) is pushed via any sequence of symbols (any string) of any length, it\n",
        "       always stays in the same type of state. Thus, after seeing 'ababba', S2 is in S6, while S3 \n",
        "        is also in S6.\n",
        "\n",
        "\n",
        " - Thus, given no changes in the matrix, we stop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "mSZP8Q4kYczg"
      },
      "source": [
        "## Code for DFA minimization\n",
        "\n",
        "We now provide the code for DFA minimization, referring to the above narrative to keep us focused as to which part of the algorithm we are implementing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "-B_Cbfu0Yczh"
      },
      "source": [
        "### The heart of the algorithm is function fixptDist. This seeks the fixpoint (or \"fixed-point\") of the Dist (or Distinguishability) relation. Neat eh?\n",
        "\n",
        "A fixpoint of a function f is a value x such that f(x) = x. In our case, the functiion in question is one that take the entire matrix (frame) and tries to spit out the next matrix (frame). When we get a matrix m such that f(m) = m, the matrix has stabilized.\n",
        "\n",
        "In our case, we obtain a fixpoint of the function with respect to input value \"ht\" (hash-table) representing our matrix. We also pass along the DFA in question (\"D\") that is a read-only argument (to consult its transition function, etc).\n",
        "\n",
        "See how the code speaks for itself:\n",
        "\n",
        "* We set \"changed = True\" outside a while loop, and enter this loop \"while changed\".\n",
        "\n",
        "* We set changed = False, hoping to get out\n",
        "\n",
        "  - Any change-causing activity (n-distinguishability for some n) will set changed back to True\n",
        "  \n",
        "  - If not, we will \"get out of the jail\"\n",
        "  \n",
        "  - Termination is guaranteed. Why?\n",
        "    \n",
        "      * There are only a finite number of states\n",
        "      \n",
        "      * If we pump a long-enough string from a pair of states,\n",
        "      \n",
        "          - Clearly, it can try to meander, visiting fresh state pairs that are m-distinguishable for \n",
        "             an m <= n (those other state pairs and their distinguishability distance\n",
        "             were generated in an earlier pass or the current pass)\n",
        "             \n",
        "      * In short, for any pair of states (p,q), there is a maximal (loop-free) string s such that \n",
        "        $\\hat{\\delta}(p,s) \\in F$ while $\\hat{\\delta}(q,s)\\in (Q\\setminus F)$. This is the highest the \n",
        "        distinguishability number can get to.\n",
        "             \n",
        "           - If $s$ has a loop, there is a shorter string that establishes the distinguishability \n",
        "              number.\n",
        "         \n",
        "         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "tS8FnUs5Yczh"
      },
      "source": [
        "We now go through all aspects of the code:\n",
        "\n",
        "* We first iterate across \"kv\" (key,value) pairs in ht.items(), i.e. we iterate through all \n",
        "  the matrix entries (pairs) which are recorded in \"ht\" (the hash table). The value recorded is the\n",
        "  distinguishability number.\n",
        "  \n",
        "* We obtain s0 and s1, the states that this hash-table entry is modeling.\n",
        "\n",
        "* We iterate across all $c\\in\\Sigma$\n",
        "\n",
        "* We obtain the next state after sending s0 and s1 via $c$\n",
        "\n",
        "* If we land in the same next state (ns0 == ns1), we continue (try to \"get out of the jail\" by not\n",
        "  resetting changed)\n",
        "  \n",
        "* If this is a visited pair (i.e. (ns0,ns1) in ht), then\n",
        "\n",
        "  - If one is \"-1\" while the other is >= 0  (meaning they are distinguishable states)\n",
        "     \n",
        "       - then we set changed = True, and continue, breaking this iteration of the \"for c\"\n",
        "       \n",
        "       - else we examine it as pair (ns1, ns0). This is because \"ht\" does not store both \n",
        "          (ns0,ns1) and (ns1,ns0). But we have to check both ways\n",
        "          \n",
        "       - we apply the same logic\n",
        "       \n",
        "* If we can find distinguishability, we increase the ht number\n",
        "\n",
        "* else we will get out of the loop!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "lsiHvLWWYczh"
      },
      "source": [
        "def fixptDist(D, ht):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            ht (hash-table of distinguishability pair distances)\n",
        "       Out: ht that has attained a fixpoint in distinguishability.\n",
        "       Helper (but main workhorse) for min_dfa.\n",
        "       Given an initial hash-table ht and a DFA D to be minimized,\n",
        "       determine the min. distinguishability distances, going frame \n",
        "       by frame, as illustrated in the DFA minimization algorithm. \n",
        "       Return fixpoint ht. Fixpoint is when ht ceases to change.\n",
        "    \"\"\"\n",
        "    changed = True\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for kv in ht.items():\n",
        "            s0 = kv[0][0]\n",
        "            s1 = kv[0][1]\n",
        "            for c in D[\"Sigma\"]:\n",
        "                ns0 = D[\"Delta\"][(s0,c)]\n",
        "                ns1 = D[\"Delta\"][(s1,c)]\n",
        "                #\n",
        "                # Distinguishable state pairs carry \n",
        "                # \"distinguishability distance\" in the ht\n",
        "                if ns0 == ns1:\n",
        "                    continue\n",
        "                if (ns0, ns1) in ht:\n",
        "                    # s0,s1 are distinguishable\n",
        "                    if ht[(s0,s1)] == -1 and ht[(ns0, ns1)] >= 0: \n",
        "                        # acquire one more than the\n",
        "                        # dist. number of (ns0,ns1)\n",
        "                        ht[(s0,s1)] = ht[(ns0, ns1)] + 1          \n",
        "                        changed = True                            \n",
        "                        break\n",
        "                else:\n",
        "                    # ht stores only (ns0,ns1); \n",
        "                    # so check the other way\n",
        "                    if (ns1, ns0) in ht:                              \n",
        "                        if ht[(s0,s1)] == -1 and ht[(ns1, ns0)] >= 0:  \n",
        "                            ht[(s0,s1)] = ht[(ns1, ns0)] + 1           \n",
        "                            changed = True                             \n",
        "                            break                                      \n",
        "                    else:                                              \n",
        "                        print(\"ht doesn't cover all reqd state combos.\")\n",
        "    return ht"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "hVQhcjTmYczh"
      },
      "source": [
        "def min_dfa(D, state_name_mode='succinct'):  # Default state mode\n",
        "    \"\"\"In : D (consistent DFA to be minimized)\n",
        "       Out: Minimized version of D.\n",
        "       The top-level callable DFA minimizer.\n",
        "       Given a DFA D, go through the state minimization algorithm.\n",
        "       state_name_mode is 'verbose' or 'succinct', producing two \n",
        "       variants, as you can guess.\n",
        "       If the state_name_mode is verbose, we will make state names\n",
        "       by stringing together the state names in the equivalence\n",
        "       classes. Else we keep the name of the representative of \n",
        "       each equivalence class.\n",
        "    \"\"\"\n",
        "    if (len(D[\"Q\"]) == 1): # Already minimal\n",
        "        return D\n",
        "    else:\n",
        "        # Build a dict of all state combinations of DFA.\n",
        "        # Function state_combos also imparts a -1 for each state pair,\n",
        "        # initializing the separation distance at -1.  \n",
        "        ht = dict(state_combos(list(D[\"Q\"])))\n",
        "    \n",
        "        # Mark final and non-final states to be 0-distinguishable.\n",
        "        # This is achieved by putting a 0 against those state pairs.\n",
        "        sepFinNonFin(D, ht)\n",
        "    \n",
        "        # Main fixpoint computation: Assigning distinguishability dist. \n",
        "        #==============================================================\n",
        "        ht = fixptDist(D, ht)\n",
        "    \n",
        "        # Pick out equivalent state-pairs, i.e. those that cannot be \n",
        "        # distinguished. These are still with a \"-1\" in ht.\n",
        "        ht_1 = [ stpair for (stpair, dist) in ht.items() if dist == -1 ]\n",
        "    \n",
        "        # Now form equivalence classes\n",
        "        # what's returned is \n",
        "        # [(rep_1, [all_eql_states_1]), (rep_2, [all_eql_states_2]),...]\n",
        "        # which includes all equivalence classes of size 2 or more.\n",
        "        rep_eqc = bash_eql_classes(ht_1)\n",
        "\n",
        "        # Now we have to deal with singleton equivalence classes. \n",
        "        # These sit unmerged, OUTSIDE OF ALL (x,y) in ht_1\n",
        "        # i.e. all the entries in ht_1 are PARTNERED STATE PAIRS.  \n",
        "    \n",
        "        # If we now take D[\"Q\"] and subtract from it all those x and y\n",
        "        # which are present in some pair in ht_1, we obtain completely\n",
        "        # non-mergable states. These are states in their own eql. classes.\n",
        "    \n",
        "        # 1. Find all partnered states from ht_1\n",
        "        Partnered_states = list({x for (x,y) in ht_1} |\n",
        "                                {y for (x,y) in ht_1})\n",
        "    \n",
        "        # 2. Now who is left un-partnered?\n",
        "        List_of_self_only_eqlt_states = listminus(D[\"Q\"], Partnered_states)                     \n",
        "    \n",
        "        # 3. For these singletons, i.e. \"self-only equivalent states\", \n",
        "        # they are self-representative. Form pairs that indicate this fact.\n",
        "        rep_eqc_1 = [(x, [x]) for x in List_of_self_only_eqlt_states]\n",
        "    \n",
        "        # 4. OK now, we can combine the set of pairs where each pair is \n",
        "        # (representative, [the list of equivalent states])\n",
        "        # So finally we get the list of equivalence classes with \n",
        "        # representatives  which is of this form:\n",
        "        # [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...] \n",
        "        final_rep_eqc = rep_eqc + rep_eqc_1\n",
        "    \n",
        "        # We are now ready to build a DFA out of final_rep_eqc. \n",
        "        # =====================================================\n",
        "    \n",
        "        # 1. First, form the set of minimized states, which are \n",
        "        # state representatives.\n",
        "        minQ = {x for (x,y) in final_rep_eqc}\n",
        "    \n",
        "        # 2. The Alpbahet remains the same.\n",
        "        minSigma = D[\"Sigma\"]\n",
        "    \n",
        "        # 3. The starting state is the representative of D[\"q0\"]\n",
        "        minq0 = q0_of(D[\"q0\"], final_rep_eqc)\n",
        "    \n",
        "        # 4. The final states are the representatives of the original\n",
        "        #    final states. This is computed by helper F_of.\n",
        "        minF = F_of(D[\"F\"], final_rep_eqc)\n",
        "    \n",
        "        # 5. The transition relation of the minimized DFA is obtained\n",
        "        #    by the helper Delta_of\n",
        "        minDelta = Delta_of(D[\"Delta\"], final_rep_eqc)\n",
        "    \n",
        "        # 6. We now need to rename the states if the user wants verbose \n",
        "        #    names (default is succinct). Verbose names are the name of \n",
        "        #    states in each equivalence class strung together sep by \"_\".\n",
        "        if state_name_mode == 'verbose':\n",
        "            # First build a state-renaming hash-table involving \n",
        "            # mk_state_eqc_name\n",
        "            state_rename_ht = { x : mk_state_eqc_name(y) \n",
        "                                for (x,y) in final_rep_eqc }\n",
        "        \n",
        "            minQ            = { state_rename_ht[x] for x in minQ }\n",
        "            minq0           = state_rename_ht[minq0]\n",
        "            minF            = { state_rename_ht[f] for f in minF }\n",
        "            minDelta = { (state_rename_ht[x], y) : state_rename_ht[z] \n",
        "                         for ((x,y),z) in minDelta.items() }\n",
        "        #\n",
        "        # Return the finished (minimized) DFA!\n",
        "        return mk_dfa(minQ, minSigma, minDelta, minq0, minF)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "h7j9BzCnYczi"
      },
      "source": [
        "def pairFR(L):\n",
        "    \"\"\"In : L (list of states)\n",
        "       Out: List of pairs with L[0] paired with each state in L[1:],\n",
        "            with the distinguishability distance initialized to -1.\n",
        "       Helper for generating state_combos.\n",
        "    \"\"\"\n",
        "    return list(map(lambda x: ((L[0], x), -1), L[1:]))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "xc3CocbtYczi"
      },
      "source": [
        "def state_combos(L):\n",
        "    \"\"\"In : L (list of states)\n",
        "       Out: List of combinations of L's states (rep. as pairs),\n",
        "            with distinguishability distances marked as -1. \n",
        "       Helper for min_dfa.\n",
        "       Given a list of DFA states L (assume length >= 2),\n",
        "       Form state combinations, paired up as (L[i], L[i+1]).\n",
        "       This forms the 'ht' that is acted upon by fixptDist.\n",
        "    \"\"\"\n",
        "    if len(L) <= 2:\n",
        "        return([((L[0], L[1]), -1)])\n",
        "    else:\n",
        "        return (pairFR(L)) + (state_combos(L[1:]))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "PcoXgfKqYczi"
      },
      "source": [
        "def sepFinNonFin(D, ht):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            ht (hash table of distinguishability distances)\n",
        "       Out: ht with (nonfinal,final) pairs in ht\n",
        "            marked with a distinguishability distance of 0.\n",
        "       Helper for min_dfa.\n",
        "       Given a hash-table of separation distances and a DFA D,\n",
        "       mark each state pair (final,non-final) with value 0\n",
        "       indicating their 0-distinguishability.\n",
        "    \"\"\"\n",
        "    # Form a separation predicate \n",
        "    sepPred = lambda x,y: (x in D[\"F\"] and y in (D[\"Q\"] - D[\"F\"]) or \n",
        "                           y in D[\"F\"] and x in (D[\"Q\"] - D[\"F\"]))\n",
        "                         \n",
        "    # Now separate all states where sepPred holds\n",
        "    for kv in ht.items():\n",
        "        if sepPred(kv[0][0], kv[0][1]):\n",
        "            # Mark that this pair is 0-distinguishable\n",
        "            ht[kv[0]] = 0"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "SZbVjhNNYczj"
      },
      "source": [
        "def bash_eql_classes(eql_reln):\n",
        "    \"\"\"In : eql_reln (equivalence relation : list of pairs of states).\n",
        "       Out: List of equivalence classes with representatives.\n",
        "            I.e. a structure of the form\n",
        "            [ (state0, [state0, state1, state2,]), ... ]\n",
        "            where state0 is a representative for the three (for example)\n",
        "            equivalent states state0, state1, state2. There are as many\n",
        "            such pairs as equivalence classes.\n",
        "       Helper for min_dfa.\n",
        "       Given an Eql. reln. of the form \n",
        "       [(a,b),(a,c),(d,e),(f,h),(g,f),..].\n",
        "       1. Grow eql classes \n",
        "       2. Elect a representative for each eql class\n",
        "       3. Return \"equivalence classes with representatives.\"\n",
        "       This is a structure of the form\n",
        "        [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...] \n",
        "       where \"a0\" is a state and a0,a1,a2,a3,a4 are equivalent to it\n",
        "       The same goes for the bs, cs, etc.\n",
        "    \"\"\"\n",
        "    return bash_1(eql_reln, []) # seed with empty list of eql class sets."
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "5wAznF8uYczj"
      },
      "source": [
        "def listminus(L1, L2):\n",
        "    \"\"\"In : L1 : list or set\n",
        "            L2 : list or set\n",
        "       Out: List of items in L1 that are not in L2.\n",
        "       Helper for min_dfa and bash_1. Implements subtraction (L1 - L2).\n",
        "    \"\"\"\n",
        "    return [x for x in L1 if x not in L2]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "LBbT2oI1Yczj"
      },
      "source": [
        "def bash_1(eql_reln, L_eq_classes):\n",
        "    \"\"\"In : eql_reln (equivalence relation : list of pairs of eqlt states)\n",
        "            L_eq_classes (list of eql classes which are SETS of states \n",
        "            for now.)\n",
        "       Out: return list of equivalence classes with representatives.\n",
        "       Helper for bash_eql_classes. \n",
        "       1) eql_reln is the current equivalence relation \n",
        "          (list of pairs)\n",
        "       2) L_eq_classes is a list of sets that are the eqlt \n",
        "          classes coalesced thus far.\n",
        "       3) We remove one pair at a time from the eql_reln and find\n",
        "          existing equivalence classes to expand, thus modifying\n",
        "          L_eq_classes each time. \n",
        "       Once the equivalence relation is emptied, we call mk_rep_eqc\n",
        "       thus making a list of equivalence classes with representatives\n",
        "       of the form \n",
        "       [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...]. \n",
        "    \"\"\"\n",
        "    if eql_reln == []:\n",
        "        # When we have fully processed the given equivalence \n",
        "        # relation, return a list of equivalence classes with \n",
        "        # representatives of the form \n",
        "        # [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...]\n",
        "        return mk_rep_eqc(L_eq_classes)\n",
        "    else:\n",
        "        # pick the next pair from the eql_reln being coalesced\n",
        "        eq0 = eql_reln[0]   \n",
        "        a = eq0[0]          \n",
        "        b = eq0[1]   \n",
        "        \n",
        "        # We know that a is a state that is equivalent to b, since\n",
        "        # they exist as a pair in eql_reln[0].\n",
        "        \n",
        "        # Now we must see if 'a' already lives in a COALESCED \n",
        "        # equivalence class\n",
        "   \n",
        "        # Set Sa is a typical equivalence class in L_eq_classes\n",
        "        # See if 'a' is in Sa.\n",
        "        \n",
        "        SaL = [Sa for Sa in L_eq_classes if a in Sa]\n",
        "        \n",
        "        # There must be zero or one such set as Sa. \n",
        "        # Thus, |SaL| = 0 or 1\n",
        "        \n",
        "        # Similarly, see which (if any) eql class that b lives in\n",
        "        SbL = [Sb for Sb in L_eq_classes if b in Sb]  \n",
        "        \n",
        "        # Now there are four cases:\n",
        "        \n",
        "        # 1. a,b pair is totally new (not in any eql. class so far)\n",
        "        if (SaL == [] and SbL == []):\n",
        "            # Add a fresh eql class {a,b} to L_eq_classes and recurse\n",
        "            return bash_1(eql_reln[1:], [{a,b}] + L_eq_classes)\n",
        "        \n",
        "        # 2. a is in eql class SaL[0] while b is not in any eql class\n",
        "        elif (SbL == [] and not(SaL == [])):\n",
        "            # Remove the little eql. class in which 'a' sits\n",
        "            # replace by a bigger eql. class that now also includes 'b'. \n",
        "            # That is, we must invite 'b' into the same eql class \n",
        "            # in which 'a' sits (this being SaL[0]).\n",
        "            \n",
        "            # Then we take away the eql class that 'a' sits in from \n",
        "            # L_eq_classes, and of course replace it with an expanded \n",
        "            # version that includes b\n",
        "            New_L_eq_classes = (listminus(L_eq_classes, SaL) +\n",
        "                                [SaL[0] | {b}])\n",
        "            \n",
        "            return bash_1(eql_reln[1:], New_L_eq_classes)\n",
        "        \n",
        "        # 3. b is in eql class SbL[0] while a is not in any eql class\n",
        "        elif (SaL == [] and not(SbL == [])):\n",
        "            # Similar steps as above, with 'a' being invited in.\n",
        "            \n",
        "            New_L_eq_classes = (listminus(L_eq_classes, SbL) +\n",
        "                                [SbL[0] | {a}])\n",
        "            \n",
        "            return bash_1(eql_reln[1:], New_L_eq_classes)\n",
        "        \n",
        "        else:\n",
        "            # a and b are both in their own little eql. classes\n",
        "            # We must now collapse both the eql classes into a huge one\n",
        "            # Remove both little pre-existing eql. classes. Replace \n",
        "            # with union-ed one. Neither 'a' nor 'b' is being invited in\n",
        "            # afresh; rather, the eql classes they are in \n",
        "            # (i.e. SaL[0],SbL[0]) are being merged.\n",
        "            \n",
        "            New_L_eq_classes = (listminus(L_eq_classes,SaL+SbL) + \n",
        "                                [SaL[0] | SbL[0]])\n",
        "            \n",
        "            return bash_1(eql_reln[1:], New_L_eq_classes)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "op6pkk-bYczj"
      },
      "source": [
        "def mk_rep_eqc(L_eq_classes):\n",
        "    \"\"\"Helper for bash_1 that finds the representative of a set of\n",
        "       equivalent states. Given the final equivalence classes,\n",
        "       make representatives for each; stick the repr. at the \n",
        "       head of a pair. Thus, (repr, eql-class-with-repr) list\n",
        "       is returned.\n",
        "    \"\"\"\n",
        "    Ll = list(map(lambda x: list(x), L_eq_classes))\n",
        "    return list(map(lambda x: (x[0], x), Ll))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "1LNqpDdMYczk"
      },
      "source": [
        "def F_of(F, final_rep_eqc):\n",
        "    \"\"\"In : F (final states of DFA)\n",
        "            final_rep_eqc : equivalence class with representatives\n",
        "       Out: A set of representatives of the final states \n",
        "       Helper for min_dfa.\n",
        "       Given F, the final states of a DFA and final equivalence\n",
        "       classes with representatives of the form \n",
        "       [(rep,[states eql to rep], ...)\n",
        "       obtain those equivalence classes in which the original final \n",
        "       states live. Form a set of the representatives of these states. \n",
        "       This will be the set of representatives of the final states.\n",
        "    \"\"\"\n",
        "    return { x for (x,X) in final_rep_eqc \n",
        "             if not (set(F) & set(X)) == set({}) }"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "qOZzHoESYczk"
      },
      "source": [
        "def rep_of_s(s, final_rep_eqc):\n",
        "    \"\"\"Helper for min_dfa. Given a list \n",
        "       [(rep_of_s1, [states_eql_to_s1]),...]\n",
        "       that has states paired with the list of equivalent states, \n",
        "       return the representative of s.\n",
        "    \"\"\"\n",
        "    if final_rep_eqc == []:\n",
        "        print(\"Error, did not find a rep for state s\")\n",
        "    else:\n",
        "        x_X = final_rep_eqc[0]\n",
        "        if s in x_X[1]:\n",
        "            return x_X[0]\n",
        "        else:\n",
        "            return q0_of(s, final_rep_eqc[1:])    "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "fFXRu3poYczk"
      },
      "source": [
        "def q0_of(q0, final_rep_eqc):\n",
        "    \"\"\"Helper for min_dfa. Given the initial state of the DFA and\n",
        "       the list [(rep, [eql states]), ...], find the representative\n",
        "       of q0 in lieu of q0.\n",
        "    \"\"\"\n",
        "    return rep_of_s(q0, final_rep_eqc)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "-cUIacjbYczk"
      },
      "source": [
        "def Delta_of(Delta, final_rep_of_eqc):\n",
        "    \"\"\"In : Delta (transition function of the given DFA)\n",
        "            final_rep_of_eqc (eql classes with representatives)\n",
        "       Out: Form a dict of representatives' moves.\n",
        "       Helper for min_dfa. \n",
        "       Given the original transition function Delta and the\n",
        "       list [(rep_of_eqc, [equivalent states,...]), ...], \n",
        "       produce a new transition function with state representatives \n",
        "       (not the original states) jumping around!\n",
        "       The nice thing is that if multiple states had jumped around, \n",
        "       their transitions AUTOMATICALLY GET MERGED when we pool \n",
        "       the transitions into a hash-table (dictionary). Thus, we are \n",
        "       merging transitions among equivalent states also.\n",
        "    \"\"\"\n",
        "    return { (rep_of_s(s0, final_rep_of_eqc), a): \n",
        "              rep_of_s(s1, final_rep_of_eqc)  \n",
        "              for  ((s0,a),s1) in Delta.items() }"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "cmIxHLyEYczl"
      },
      "source": [
        "def mk_state_eqc_name(L):\n",
        "    \"\"\"In : List of states (in each eql class)\n",
        "       Out: single state names by bashing the states separated by \"_\".\n",
        "       Helper for min_dfa. \n",
        "       Given a list of states, bash the \n",
        "       state names together separated by an underscore. \n",
        "       This is useful when 'verbose mode' state name printing \n",
        "       is desired.\n",
        "    \"\"\"\n",
        "    return \"_\".join(L)"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}